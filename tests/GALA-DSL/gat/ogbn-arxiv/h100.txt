// Init data
G = load_dataset("ogbn-arxiv");

aggrFn = dsl.get_aggregate(fn = dsl.fn.mul_sum);
edgeFn = dsl.get_edge_aggregate(fn = dsl.fn.sum);
L1 = layer(G, hs, nonln_fn, aggregate_fn, edge_fn) {
    res = dsl.nn.ffn(G.node.feats, out=hs);
    attnL = dsl.nn.ffn(res, out=1);
    attnR = dsl.nn.ffn(res, out=1);
    attn = edge_fn(G, attnL, attnR);
    G.edges.vals = dsl.fn.softmax(G, attn);
    res = aggregate_fn(G.graphs, res);
    G.node.feats = nonln_fn(res);
}

M1 = model(G, non_ln) {
	l1 = L1(G, 32, non_ln, aggrFn, edgeFn);
	l2 = L1(l1, G.labels.size(), null, aggrFn, edgeFn);
}

m1 = M1(G, dsl.non_ln.ReLU);
m1.train(iters=100, validation_step=5);
res = m1.eval();

# schedule
G=G.set_unweighted(true); // false by default
feature_size(128); // -2 if not given
label_size(40); // -3 if not given
// Compute transformations
aggrFn=aggrFn.coarsen(4);