// Init data
G = load_dataset("ogbn-arixv");

aggrFn = dsl.get_aggregate(fn = dsl.fn.mul_sum);
L1 = layer(G, hs, nonln_fn, aggregate_fn) {
    res_n = aggregate_fn(G.graphs, G.node.feats);
    res = dsl.nn.scalar(1) * G.node.feats;
    res = res + res_n;
    res = dsl.nn.ffn(res, out=hs);
    G.node.feats = nonln_fn(res);
}

M1 = model(G, non_ln) {
	l1 = L1(G, 32, non_ln, aggrFn);
	l2 = L1(l1, G.labels.size(), non_ln, aggrFn);
}

m1 = M1(G, dsl.non_ln.ReLU);
m1.train(iters=100, validation_step=5);
res = m1.eval();

# schedule
G=G.set_unweighted(true); // false by default
feature_size(128); // -2 if not given
label_size(40); // -3 if not given
// Compute transformations
aggrFn=aggrFn.coarsen(4);