// Init data
G = load_dataset("Reddit");

aggrFn = dsl.get_aggregate(fn = dsl.fn.mul_sum);
L1 = layer(G, hs, leakyRelu_fn, nonln_fn, aggregate_fn) {
    res = dsl.nn.ffn(G.node.feats, out=hs);
    l_side = dsl.nn.init_weight() * res.src; // TODO: change this to be dictionary map style instead?
    r_side = dsl.nn.init_weight() * res.dst; // prob not correct?
    res = dsl.non_ln.LeakyReLU(l_side+r_side); // prob should change to function parameter not dsl.xx.xxx
    res = dsl.fn.softmax(res);
    res = aggregate_fn(G.graphs, res);
    res = nonln_fn(res);
}

M1 = model(G, non_ln) {
	l1 = L1(G, 32, non_ln, aggrFn);
	l2 = L1(l1, G.labels.size(), non_ln, aggrFn);
}

m1 = M1(G, dsl.non_ln.ReLU);
m1.train(iters=100, validation_step=5);
res = m1.eval();

# schedule
G=G.set_undirected(true); // false by default
G=G.set_unweighted(true); // false by default
feature_size(605); // -2 if not given 
label_size(41); // -3 if not given 
// Compute transformations
aggrFn=aggrFn.coarsen(2);
// Data transformations
G=G.col_tile(37000);